import sqlite3
import json
import requests
from bs4 import BeautifulSoup
# Adicione outras bibliotecas de Web Scraping (como Selenium) aqui quando necess√°rio

DB_NAME = 'elite_critics.db'

def conectar_bd():
    """Conecta ao banco de dados SQLite."""
    return sqlite3.connect(DB_NAME)

def obter_info_basica_filme(slug_filme):
    """
    SIMULA√á√ÉO DE WEB SCRAPING: Obt√©m informa√ß√µes b√°sicas do filme.
    Retorna um dicion√°rio com os dados.
    """
    # A URL real usa underscore, como voc√™ observou
    url_base = f"https://www.rottentomatoes.com/m/{slug_filme}"
    print(f"\n--- Web Scraping I: {url_base} ---")
    
    # --- SIMULA√á√ÉO DE DADOS PARA TWILIGHT (2008) ---
    if slug_filme == 'twilight':
        return {
            'url_filme': '/m/twilight',
            'nome': 'Twilight (2008)',
            'nota_rt': 49,  # Pontua√ß√£o real: 49%
            'generos': 'Fantasy, Romance, Drama, Adventure'
        }
    
    # Em um programa real, voc√™ faria a requisi√ß√£o aqui
    print("Implementa√ß√£o futura: Requisi√ß√£o HTTP para a URL do filme.")
    return None

def inserir_filme(filme_data):
    """Insere ou atualiza os dados do filme na tabela Filme."""
    conn = conectar_bd()
    print ("Conectado ao banco de dados!")
    cursor = conn.cursor()
    try:
        # Usamos REPLACE INTO para garantir que a chave √∫nica (url_filme) seja respeitada
        cursor.execute("""
            REPLACE INTO Filme (url_filme, nome, nota_rt, generos, nota_ndci, nota_ndcii)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            filme_data['url_filme'],
            filme_data['nome'],
            filme_data['nota_rt'],
            filme_data['generos'],
            None, # NDCI - Em Constru√ß√£o
            None  # NDCII - Em Constru√ß√£o
        ))
        conn.commit()
        print(f"Filme '{filme_data['nome']}' inserido/atualizado com sucesso.")
    except sqlite3.Error as e:
        print(f"Erro ao inserir filme: {e}")
    finally:
        conn.close()

def main():
    """
    Fun√ß√£o principal do Elite Critics.
    """
    # --- Passo 1: Entrada do Usu√°rio (Simulada) ---
    filme_slug = 'twilight'
    print(f"üé¨ Iniciando an√°lise para o filme: {filme_slug}")

    # --- Passo 2: Web Scraping I e Inser√ß√£o na BD ---
    filme_data = obter_info_basica_filme(filme_slug)
    
    if not filme_data:
        print("Erro: N√£o foi poss√≠vel obter dados b√°sicos do filme.")
        return

    inserir_filme(filme_data)
    
    # --- Passo 3: Apresenta√ß√£o das Notas ---
    print("\n" + "="*50)
    print(f"üèÜ Resultados de Elite Critics para: {filme_data['nome']}")
    print("="*50)
    
    print(f"1. Tomatometer (Rotten Tomatoes Original): {filme_data['nota_rt']}%")
    
    # O Popcornmeter precisaria de outro Web Scraping
    print("2. Popcornmeter (Audience Score Original): 59% (SIMULA√á√ÉO)")
    
    print("\n--- C√°lculos Recalculados ---")
    print("3. Nota dos Cr√≠ticos I - No Room for Noobies (NDCI): Em Breve/Constru√ß√£o")
    print("4. Nota dos Cr√≠ticos II - Hierarchy (NDCII): Em Breve/Constru√ß√£o")
    
    # --- Passos Futuros (Comentados para evitar erro de c√≥digo) ---
    # print("\n--- Pr√≥ximos Passos (Web Scraping II & Processamento) ---")
    # 1. Chamar Web Scraping II (Reviews): Obter lista de cr√≠ticos e notas.
    # 2. Iniciar La√ßo 1 (Por Cr√≠tico): 
    #    - Se cr√≠tico novo, chamar Web Scraping III para lista de filmes.
    #    - Iniciar La√ßo 2 (Por Filme Avaliado) e consultar/scraping a tabela Filme para obter G√™nero e calcular Experi√™ncia/Rank.
    # 3. Calcular NDCI e NDCII.

if __name__ == '__main__':
    # Garante que o banco de dados existe antes de tentar rodar o programa principal
    try:
        conectar_bd().close()
    except:
        print("Erro: O arquivo 'elite_critics.db' pode n√£o existir. Rode 'CreateTables.py' primeiro.")

    main()